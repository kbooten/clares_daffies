{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clare's Daffies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"Thus, only when the making of the 'nation', an entirely abstract group based on law, creates new usages and functions does it become indispensible to forge a *standard* language, impersonal and anonymous like the official uses it has to serve, and by the same token to undertake the work of normalizing the products of the linguistic habitus.\" (Bourdieu, _Language and Symbolic Power_)\n",
    "\n",
    ">\"A contemporary review of _Poems Descriptive_ in the _New Monthly Magazine_ (March 1820) scornfully describes several of Clare's dialect words, such as _bangs_, _chaps_, _eggs on_, _fex_, _flops_, _sniftling_ and _snufting_, as 'mere vulgarisms, and may as well be excluded from the political lexicon, as they have long since been banished from the dictionary of polite conversation.'\"  (McKusick, _John Clare and the Tyranny of Grammar_)\n",
    "\n",
    "In this notebook, I attempt to sift through John Clare's verse, capturing and collecting the \"vulgarisms\" that mark Clare, and through which Clare marks himself, as \"A Northamptonshire Peasant.\"  As McKusick notes (citing John Barrell and Timothy Brownlow), Clare's use of these words was a way of resisting \"enclosure\":\n",
    "\n",
    ">\"...Clare's conception of language and his conception of landscape seem cloasely related; he regards both as ideally constituting an unrestircted communal zone, open to local browsing and free from the linearty, exclusivity, and standardization imposed by outside authorities.\"\n",
    "\n",
    "Authorities, we might add (following Bourdieu), of _the nation_. \n",
    "\n",
    "My goal here is not really to produce any positive knowledge about Clare's diction.  Rather it is to generate a closed vocabulary (a linguistic \"palette\") of Clare-isms that may be then be put to use as the raw-material of quasi-imitative writing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Clare\n",
    "\n",
    "First I must gather some of Clare's verse.  I turn to three posthumously published collections downloaded from Project Gutenberg: _Life and Remains of John Clare_ (1872), _Poems_ (1901), _Poems Chiefly from Manuscript_ (1920).  Nb: According to McCusick, even Clare's earliest editors were quick to edit the poet's linguistically-unruly (read _anti-tyranical_) verse; no doubt the texts available on Gutenberg are already at least one step away from the Clare found in his manuscripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clarefiles = [\"clare52601.txt\",\"clare8672.txt\",\"clare9156.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gutenberg.cleanup import strip_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "claretext = \"\"\n",
    "\n",
    "for c in clarefiles:\n",
    "    with open(c,'r') as f:\n",
    "        ct_temp = strip_headers(f.read().decode('utf-8'))\n",
    "        claretext+=\" \"+ct_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Project Gutenberg versions of Clare's texts contain plenty of editorial commentary.  I'll use a regular expression to try to only match Clare's verse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanzas = re.findall(r'(?:[A-Z].+[a-z].+\\n *){3,}',claretext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stanzas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(\"fex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time looks on pomp with vengeful mood\n",
      "  Or killing apathy's disdain;\n",
      "So where old marble cities stood\n",
      "  Poor persecuted weeds remain.\n",
      "She feels a love for little things\n",
      "  That very few can feel beside,\n",
      "And still the grass eternal springs\n",
      "  Where castles stood and grandeur died.\n",
      "\n",
      "***\n",
      "The boy, that scareth from the spiry wheat\n",
      "  The melancholy crow--in hurry weaves,\n",
      "  Beneath an ivied tree, his sheltering seat,\n",
      "  Of rushy flags and sedges tied in sheaves,\n",
      "  Or from the field a shock of stubble thieves.\n",
      "  There he doth dithering sit, and entertain\n",
      "  His eyes with marking the storm-driven leaves;\n",
      "  Oft spying nests where he spring eggs had ta'en,\n",
      "And wishing in his heart twas summer-time again.\n",
      "\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "for i in random.sample(stanzas,2):\n",
    "    print i\n",
    "    print \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanzas_joined = \" \".join(stanzas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out repeat lines and rejoin into a big string'o'Clare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13150\n",
      "11664\n"
     ]
    }
   ],
   "source": [
    "lines = stanzas_joined.split(\"\\n\") \n",
    "lines = [l.strip() for l in lines]\n",
    "print len(lines)\n",
    "lines = list(set(lines))\n",
    "print len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_clare_lines = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I doubt I can use a standard tokenizer because I don't want to break up Clare's nonstandard contractions.  An example of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['And', 'all', 'thy', 'pastures', 'plough', \"'d\", '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.word_tokenize(\"And all thy pastures plough'd.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `plough'd` would be better off kept as one word.  I'll just have to roll my own tokenizer---one that, however imperfect, will at least try to respect Clare's orthography. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_tokenize(abigstring):\n",
    "    \"\"\"\n",
    "    Note: I don't fool with lowering strings.  Too hard to keep out proper nouns.\n",
    "    \"\"\"\n",
    "    tokens = abigstring.split()\n",
    "    tokens = [w.replace(u'\\u2019',\"'\") for w in tokens] ## replace unicode apostrophe with ascii apostrophe (better for regex searches)\n",
    "    tokens = [re.sub(r\"[^a-z']+$\",'',w) for w in tokens] ## remove trailing non-alpha characters or single quote (e.g. punctuation)\n",
    "    tokens = [re.sub(r\"'s$\",\"\",w) for w in tokens] ## remove possessive: 's\n",
    "    tokens = [re.sub(r\"s'$\",\"s\",w) for w in tokens] ## remove possessive: s'\n",
    "    tokens = [t for t in tokens if len(t)>0] ## remove 0-length strings\n",
    "    tokens = [t for t in tokens if re.match(r\"^[a-z']+-?[a-z']+$\",t)] ## only keep words that consist of a-z, ', -.  \n",
    "    tokens = [t for t in tokens if re.match(r\"[ivx]+$\",t)==None] ## remove roman numerals\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clare_tokens = custom_tokenize(all_clare_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clare_vocab = list(set(clare_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8308"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clare_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Against Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious way to isolate those words that characterize Clare's \"vulgar\" vocabular is to filter out words that appear in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enchant\n",
    "dictionary = enchant.Dict(\"en_GB\")\n",
    "dictionary.check(\"salmon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clare_vocab_not_in_dictionary = [w for w in clare_vocab if (dictionary.check(w)==False)]\n",
    "clare_vocab_not_in_dictionary = [w for w in clare_vocab_not_in_dictionary if dictionary.check(w.replace(\"-\",\"\"))==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clare_vocab_not_in_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the words we've caught..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'shepherd-skill',\n",
       " u'wind-floating',\n",
       " u'veigled',\n",
       " u'dew-wet',\n",
       " u'summer-shorn',\n",
       " u'meek-eyed',\n",
       " u'unbought',\n",
       " u'summer-grass',\n",
       " u'tinty',\n",
       " u'flower-loving']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(clare_vocab_not_in_dictionary,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Against Other Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary I have used above is no doubt biased toward modern usage and spelling.  One remedy is to further filter out words used by other writers---Browning, Hopkins, Wordsworth, etc.---under the twin assumptions that 1) such words may be anachronisms, not vernacular words, and that 2) if they are indeed vernacular terms, it is still worth filtering them out to leave behind those words that are most specific to Clare and his Northamptonshire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_to_compare = [\n",
    "        37452, ## browning vol 1 \n",
    "        33363, ## browning vol 2\n",
    "        22403, ## hopkins\n",
    "        29091, ## coleridge vol 1\n",
    "        29092, ## coleridge vol 2\n",
    "        10219, ## wordsworth vol 1\n",
    "        12145, ## v2\n",
    "        12383, ## v3\n",
    "        32459, ## v4\n",
    "        56361, ## v5\n",
    "        47651, ## v6\n",
    "        47143, ## v7\n",
    "        52836, ## v8\n",
    "        14353, ## swift vol 1\n",
    "        13621, ## swift vol 2\n",
    "        4800,  ## shelley\n",
    "        14100, ## barbauld\n",
    "        100,   ## complete shakespeare \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gutenberg.acquire import load_etext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison_tokens = []\n",
    "\n",
    "for t in texts_to_compare:\n",
    "    text = strip_headers(load_etext(t)).strip()\n",
    "    comparison_tokens+=list(set(custom_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison_tokens = list(set(comparison_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53582"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comparison_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clariest_clare_vocab = list(set(clare_vocab_not_in_dictionary).difference(set(comparison_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clariest_clare_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method filtered out nearly 50% of the words that made it through the dictionary-based filtration above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'worship-moving',\n",
       " u'beesom',\n",
       " u'whitethorns',\n",
       " u'bent-stalks',\n",
       " u'glibbed',\n",
       " u'heart-bred',\n",
       " u'wind-floating',\n",
       " u'stingo',\n",
       " u'matty',\n",
       " u'nipt',\n",
       " u'hour-telling',\n",
       " u'cag',\n",
       " u'sheep-boy',\n",
       " u'drabbled',\n",
       " u'tottergrass',\n",
       " u\"cowslip-yellow'd\",\n",
       " u'sprunts',\n",
       " u'brustling',\n",
       " u'impersonifying',\n",
       " u\"o'er-top't\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(clariest_clare_vocab,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a start. It would remain for further socio-linguistic analysis to determine the degree to which these words index class, geography, or both.  No doubt some of them (perhaps especially the compound words) are Clare's neologisms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Frequently Used Non-Standard Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of these terms, which does Clare tend to use the most frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clariest_clare_tokens = [t for t in clare_tokens if t in clariest_clare_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'oer', 84),\n",
       " (u'agen', 20),\n",
       " (u'mither', 13),\n",
       " (u'neath', 7),\n",
       " (u\"crop't\", 6),\n",
       " (u'passer-bye', 5),\n",
       " (u'brither', 5),\n",
       " (u'morts', 4),\n",
       " (u'pilewort', 4),\n",
       " (u'sen', 4),\n",
       " (u'milk-pail', 4),\n",
       " (u'trotty', 4),\n",
       " (u'blebs', 3),\n",
       " (u'stoven', 3),\n",
       " (u'whisp', 3),\n",
       " (u'adry', 3),\n",
       " (u'flye', 3),\n",
       " (u'lambtoe', 3),\n",
       " (u'blea', 3),\n",
       " (u'wirl', 3),\n",
       " (u'closen', 3),\n",
       " (u'tyrant-like', 3),\n",
       " (u'stye', 3),\n",
       " (u'crimpled', 3),\n",
       " (u'chittering', 3),\n",
       " (u'yer', 3),\n",
       " (u'hing', 3),\n",
       " (u'leuks', 3),\n",
       " (u'gipsey', 3),\n",
       " (u'dog-rose', 3),\n",
       " (u\"choak'd\", 3),\n",
       " (u'chelping', 3),\n",
       " (u'bevering', 2),\n",
       " (u'yellowcups', 2),\n",
       " (u'thegither', 2),\n",
       " (u'abouten', 2),\n",
       " (u'pig-stye', 2),\n",
       " (u'gravemounds', 2),\n",
       " (u'firetail', 2),\n",
       " (u'rewardings', 2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(clariest_clare_tokens).most_common(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Terms into Linguistic Palettes\n",
    "\n",
    "Here I very slightly adapt some code [posted to StackExchange](https://stats.stackexchange.com/a/158090) by [Lyndon White](https://stats.stackexchange.com/users/36769/lyndon-white).  It uses Affinity Propagation with Levenshtein distance to cluster terms that are orthographically similar.  I've separated words that are compounds from those that are not. \n",
    "\n",
    "In my mind, the resulting clusters together form _word-palettes_.  Organized but messy.  Discretized but blended. Ready-to-hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - *causey:* blushy, causey, chuffy, closen, couzen, daiseys, farder, gipsey, husseys, rosey\n",
      " - *weals:* deafed, knaps, knarls, leuks, oceanly, weal'd, wealed, weals, wearp, wheatlands, wheats\n",
      " - *wates:* babels, daffies, extacies, lambtoe, larkheels, mavis, oaktree, pratensis, swaliest, tauks, turnest, wa'n't, wanness, watchet, waterlilies, wates, whateer, witherest\n",
      " - *crizzled:* crimpled, crinked, crizzle, crizzled, drabbled, mizzled\n",
      " - *hummings:* hemmings, hummings, huzzing, thumming\n",
      " - *uncradled:* enchantedly, suncrackt, uncradled, unmended, upbraideth\n",
      " - *soodly:* bonnily, drowny, knowly, pooty, shily, shool, sloomy, soodle, soodles, soodly, stoney, trotty\n",
      " - *nipt:* chirrupt, copt, dib, nighty, nip't, nipt, untill, wirl\n",
      " - *cowpond:* coppled, cowpond, horsepond, scolloped, snowspots\n",
      " - *slive:* ashtree, flaze, ladslove, slive, sliveth, sybilline, ungive, whisp, ye've\n",
      " - *pol'ant'us:* pol'ant'us, pol'ant'uses, polyanthus\n",
      " - *milkpail:* firetail, milkpail\n",
      " - *jolls:* convolvulus, hollos, holm, joll, jolls, morts, woolpacks, zooks\n",
      " - *flittings:* flittings, flybitten, skirtings\n",
      " - *blow'd:* 'lowed, besom'd, blow'd, clamm'd, elbow'd, flowret, gloworms, ivy'd, snow'd, uncloy'd\n",
      " - *brither:* 'tither, blithsome, blythe, briary, bridemen, brither, ither, mither, prythee, th'other, thegither\n",
      " - *soodling:* croodling, oddling, soodling, stubbling, swopping, tokening, woodride\n",
      " - *fodderers:* daffodillies, fodd'rers, fodderers\n",
      " - *beclothed:* beclothed, becrowded, beglossed, blackletter\n",
      " - *sprunts:* bepaints, furmety, sprent, sprunts, stubbs, sychophants\n",
      " - *elderns:* clampers, eldern, elderns, elmtree, endanger'd, glorys, gudgeons\n",
      " - *unroosting:* birdnesting, jogtrotting, uniforming, unroosting\n",
      " - *thurrows:* restharrow, thornbush, thurrows\n",
      " - *renten:* abouten, bemoisten, gentlier, helpen, morehen, pendil, plantin, renten, wheneer\n",
      " - *eolian:* begolden, bookman, earlily, eolian, folken\n",
      " - *kay:* adry, cag, flaggy, kay, kew, kiby, knaw, mag, matty, rawky, swaly, taw\n",
      " - *skye:* aspin, dryed, e'e, flye, gude, kye, lyes, prog, skye, skys, stye\n",
      " - *oerstride:* oerstride, outstript, waterstrife\n",
      " - *neath:* dyeth, leaveth, neath, neatherd, neet, owneth, pleachy, scareth\n",
      " - *boundings:* boundings, groundlark, mouldiwarps, rewardings, tauntings\n",
      " - *struttles:* marygolds, sowthistles, struttle, struttles\n",
      " - *blea:* blea, bleb, blebs, bluecap, claes, embued, gleed, leal\n",
      " - *swees:* breeks, greeny, somehew, swee, swees, swops, tasseled, tween, twere\n",
      " - *tolters:* corderoy, dotterels, suthers, swelter'd, toltering, tolters, topers, tottergrass\n",
      " - *pockie:* cockchafer, concludeth, cowcribs, packman, paigle, pockie, pounc'd, puddock, rockie, stockdove\n",
      " - *taen:* agen, cauna, maken, sen, stoven, taen, taks, taws, trepan\n",
      " - *weedling:* meddlings, overswelling, speedless, sweetbriar, veigling, weedling, weedlings, yeilding\n",
      " - *lacework:* hazlewood, lacework, ladysmocks, pilewort\n",
      " - *chittering:* chickering, chitter, chittering, utterings, whitethorns\n",
      " - *glibbed:* blebbed, glabber, glibbed, grudg'd, unrobed, veigled, yminted\n",
      " - *sueing:* bevering, brustling, chelping, ekeing, elting, fast'ning, glegging, quarreling, rouzing, sawning, skreeking, sueing, suthering, sweeing\n",
      " - *soil'st:* deal'st, seem'dst, smild'st, soil'st, stil'd, stonepit, won'st, writ'st\n",
      " - *o'ershadow'd:* o'ershading, o'ershadow'd, oershadowed\n",
      " - *oer:* 'ere, derry, keck, mong, muir, oer, oerflow, ower, sober'd, wen, yer, yoe\n",
      " - *oercome:* 'kerchief, beesom, kirchup, moorcock, newcome, oercast, oercome, orchis, overbaked\n",
      " - *hings:* darings, hing, hings, kingcup, progs, shin'd, stingo, tinty\n",
      " - *untith'd:* hurtel'd, unattain'd, uncurv'd, undevoid, unsatiated, untith'd\n",
      " - *craking:* 'ticing, cacklings, cardamine, choaking, craking, crumping, doatingly, pranking, trancing, wrang\n",
      " - *choak'd:* checkered, choak'd, click'd, cloth'd, crop't, freck'd, smoaked, sneak'd\n",
      " - *siller:* gilliflowers, hilled, pilfer'd, siller, sizable, sulphury\n",
      " - *ruckles:* cuckaball, dropples, hurkles, i'cles, recordless, ruckles, ruddled\n",
      " - *cumberous:* bumbarrels, culverkey, cumberous, gravemounds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import editdistance\n",
    "\n",
    "words = [w for w in clariest_clare_vocab if \"-\" not in w]\n",
    "words = np.asarray(words) \n",
    "lev_similarity = -1*np.array([[int(editdistance.eval(w1,w2)) for w1 in words] for w2 in words])\n",
    "\n",
    "affprop = sklearn.cluster.AffinityPropagation(affinity=\"precomputed\", damping=0.5)\n",
    "affprop.fit(lev_similarity)\n",
    "for cluster_id in np.unique(affprop.labels_):\n",
    "    exemplar = words[affprop.cluster_centers_indices_[cluster_id]]\n",
    "    cluster = np.unique(words[np.nonzero(affprop.labels_==cluster_id)])\n",
    "    if len(cluster)>1:\n",
    "        cluster_str = \", \".join(cluster)\n",
    "        print \" - *%s:* %s\" % (exemplar, cluster_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - *water-pots:* hazel-roots, lavender-cotton, miller-thumbs, pale-tops, spire-points, valley-depths, wash-pools, water-porridge, water-pots, water-pudge\n",
      " - *haw-tree:* a-dry, cat-tail, haw-tree, hay-time, heart-bred, hive-bees, oak-bridge\n",
      " - *rise-not:* dust-spot, frost-nip, grass-hid, mouse-ear, rise-not, rush-beds, time-torn, white-nosed\n",
      " - *bird-boy:* barn-hole, bee-fly, bird-boy, hard-burnt, high-lows, horse-boy, king-cup, lily-bud, mid-wood, night-brown, night-sky, passing-by, pig-stye, sheep-boy\n",
      " - *dew-laden:* dew-besprent, dew-falling, dew-laden, dew-wet, dog-badger, new-laying, new-leaved\n",
      " - *sow-grass:* honey-dreams, ribbon-grass, sheep-trays, slop-frock, snow-cap't, sow-grass, sun-crack'd, wood-grass\n",
      " - *power-mocking:* copper-coloured, flower-loving, morrow-morning, power-mocking, wonder-working\n",
      " - *blossom-seeking:* blossom-haunting, blossom-seeking, bosom-stirring, woolly-fleecing\n",
      " - *pearl-like:* breast-high, buttercup-like, early-risers, heart-glow, honeycomb-like, mist-like, pearl-like, penny-praise, speak-proclaim, tumbler-like, tyrant-like, unchristian-like\n",
      " - *fern-strewn:* far-outstretching, fern-smothered, fern-strewn, leaf-strewn\n",
      " - *pond-head:* bent-head, dead-hued, downy-headed, fancy-play, home-fed, lion-hunters, mad-hearted, moor-hen, pint-horn, pond-head, pooty-shells, spring-head, wood-fiend\n",
      " - *a-blowing:* a-blowing, a-flying, a-fooling, a-milking, a-morn, a-peeping, a-walking, a-winding, all-glorious, lawn-bursting, may-bloom, up-blazing, wind-floating\n",
      " - *shepherd-dogs:* shepherd-dogs, shepherd-skill\n",
      " - *horse-chesnut:* horse-chesnut, horse-chestnut, horseshoe-circled\n",
      " - *hay-scented:* death-smitten, hawthorn-scented, hay-scented, non-identity, short-sleeved, well-scoured\n",
      " - *half-wasted:* all-mastering, half-hungry, half-smother'd, half-wasted, joke-matter, long-waited, self-consumer, self-gratified\n",
      " - *basket-bearing:* basket-bearing, bramble-berries, danger-daring, fast-approaching, jacket-buttons, mortar-bearing, tweeting-churring, warmest-seeming\n",
      " - *fine-turned:* fine-turned, last-earn'd, minstrel-throngs, simple-worded, smoke-tanned, well-turned\n",
      " - *whip-sticks:* bent-stalks, make-shifts, whip-sticks, willow-wicks, woe-stricken\n",
      " - *music-making:* magic-lanthorns, milking-maidens, murder-aiming, music-making, sunny-shining, worship-moving\n",
      " - *red-rose:* barley-crust, cabbage-roses, cart-house, dog-rose, even-pool, hedge-rose, laurel-crowned, moss-rose, new-rooted, red-rose, shy-come, tree-creeper\n",
      " - *rose-blossoms:* busy-clamorous, maiden-blossom, out-blushes, rose-blossoms\n",
      " - *straw-littered:* lowly-muttered, straw-litter'd, straw-littered, straw-thatched\n",
      " - *time-weathered:* time-weather'd, time-weathered, wind-enamoured\n",
      " - *meadow-lake:* meadow-bridge, meadow-gap, meadow-lake, meadow-rings, shadow-pillowed\n",
      " - *thunder-sound:* cumber-grounds, thunder-melting, thunder-sound\n",
      " - *stock-doves:* cuckoo-flowers, stock-doves, stockdove-flocks, storm-driven\n",
      " - *acorn-cups:* acorn-cups, corner-chair, staghorn-shaped, thorn-clump\n",
      " - *oer-topt:* fog-wet, men-gods, moor-cock, o'er-top't, oer-topt, other-country, round-topt\n",
      " - *green-leaf:* curled-leaf, garden-walls, green-leaf, green-swathed, grief-wrung, pea-leaf, threshing-floor, wreck-mere\n",
      " - *black-eyed:* billet-wood, black-cap, black-eyed, black-spotted\n",
      " - *wood-lark:* blood-walls, cloud-rack, soot-black, weed-beds, wood-brow'd, wood-fly, wood-gate, wood-harmony, wood-lark, wood-paths, wood-shady, woodbine-flowers, woodland-ride\n",
      " - *dim-powdered:* daisy-covered, dim-powdered, rime-bepowder'd, sun-reddened, velvet-bordered\n",
      " - *mock-peace:* milk-pail, mock-peace, mock-truce, mockery-ere, scarce-perceiv'd\n",
      " - *hour-telling:* cloud-resting, ever-fresh'ning, heart-aching, heart-feeding, holiday-enjoying, hour-telling, out-sobbing, school-calling\n",
      " - *winter-night:* clitter-clatter, market-night, nectar-draughts, self-delight, winter-night\n",
      " - *stone-blue:* fortune-book, home-close, signal-calls, song-cloud, stone-blue, stone-pit, stranger-place, witchen-branches\n",
      " - *parch-lipped:* arch-emperor, parch-lipped, parched-lipped\n",
      " - *cloud-bedappled:* cloud-bedappled, cloud-betravelled\n",
      " - *pasture-gate:* cottage-garden, passer-bye, pasture-gate, pasture-hill, pasture-side, picture-pasted\n",
      " - *flag-leaves:* ash-leaves, fern-leaves, flag-leaves, flag-pool, flag-retreat, plough-teams\n",
      " - *red-winged:* briar-entangled, broad-brimm'd, dew-misted, red-legged, red-winged, rib-marked, root-fringed, rut-rifted, wassail-singer\n",
      " - *summer-seat:* butter-bump, shilly-shally, shunning-hermit, summer-grass, summer-health, summer-seat, summer-shorn, suppering-up\n",
      " - *cowslip-yellow'd:* cowslip-peeps, cowslip-yellow'd\n"
     ]
    }
   ],
   "source": [
    "words = [c for c in clariest_clare_vocab if \"-\" in c]\n",
    "words = np.asarray(words) \n",
    "lev_similarity = -1*np.array([[int(editdistance.eval(w1,w2)) for w1 in words] for w2 in words])\n",
    "\n",
    "affprop = sklearn.cluster.AffinityPropagation(affinity=\"precomputed\", damping=0.5)\n",
    "affprop.fit(lev_similarity)\n",
    "for cluster_id in np.unique(affprop.labels_):\n",
    "    exemplar = words[affprop.cluster_centers_indices_[cluster_id]]\n",
    "    cluster = np.unique(words[np.nonzero(affprop.labels_==cluster_id)])\n",
    "    if len(cluster)>1:\n",
    "        cluster_str = \", \".join(cluster)\n",
    "        print \" - *%s:* %s\" % (exemplar, cluster_str) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
